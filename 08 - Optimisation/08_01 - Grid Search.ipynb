{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08.01 - Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is \"grid searching\"? What are \"hyperparameters\"?\n",
    "\n",
    "Models often come with built-in configurations that allow us to fine-tune our results. For instance, when selecting a linear regression model, we might opt to add a penalty to the loss function, such as Ridge or Lasso. These penalties require setting a regularization strength, denoted as alpha.\n",
    "\n",
    "**These configurations are known as hyperparameters.**\n",
    "\n",
    "Hyperparameters differ from the parameters of the model obtained after fitting, like the coefficients. They are predefined before fitting the model—usually during instantiation—and significantly influence the model's behavior.\n",
    "\n",
    "A model often has multiple hyperparameters to configure. For example, in the K-Nearest Neighbors (KNN) algorithm, we need to set the number of neighbors as a hyperparameter. We also need to configure the weights, which can be either uniform or distance-based. Typically, our goal is to find the *optimal* hyperparameter settings that yield the best model performance.\n",
    "\n",
    "**The process of finding the optimal set of hyperparameters is called grid searching.**\n",
    "\n",
    "Grid searching gets its name from the idea of exploring a \"grid\" of parameters. For instance, imagine plotting the `n_neighbors` hyperparameter on the x-axis and `weights` on the y-axis, testing all possible combinations on this grid.\n",
    "\n",
    "**Grid searching employs cross-validation internally to evaluate the performance of each hyperparameter set.** More on this will be discussed later.\n",
    "\n",
    "## Data\n",
    "\n",
    "To delve into the grid search process over various sets of hyperparameters, we will utilize basketball statistics from NBA seasons spanning 2013 to 2016.\n",
    "\n",
    "- This dataset comprises aggregated statistical data for each game within these seasons.\n",
    "- The aggregation is done by match for all players involved in the game.\n",
    "- The data has been sourced from [http://www.basketball-reference.com](http://www.basketball-reference.com/).\n",
    "\n",
    "Many columns in the dataset represent the average of a particular statistic over the last 10 games. Importantly, these statistics are related to *previous* games and do not contain information about player performance in the current game.\n",
    "\n",
    "**Our primary goal is to predict whether the home team will win the game or not, framing this as a classification problem.**\n",
    "\n",
    "### Loading the Data and Preparing the Target and Predictor Matrix\n",
    "\n",
    "- The target variable will be a binary column indicating whether the home team wins the game.\n",
    "- The predictor variables will be the numeric statistics columns from the dataset.\n",
    "\n",
    "We will exclude the following columns from the predictor matrix as they do not contribute to the statistical modeling:\n",
    "\n",
    "```\n",
    "['GameId','GameDate','GameTime','HostName','GuestName','total_score','total_line','game_line','winner','loser','host_wins','Season']\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>GameId</th>\n",
       "      <th>GameDate</th>\n",
       "      <th>GameTime</th>\n",
       "      <th>HostName</th>\n",
       "      <th>GuestName</th>\n",
       "      <th>total_score</th>\n",
       "      <th>total_line</th>\n",
       "      <th>game_line</th>\n",
       "      <th>Host_HostRank</th>\n",
       "      <th>...</th>\n",
       "      <th>gPTS_avg10</th>\n",
       "      <th>gTS%_avg10</th>\n",
       "      <th>g3PAR_avg10</th>\n",
       "      <th>gFTr_avg10</th>\n",
       "      <th>gDRB%_avg10</th>\n",
       "      <th>gTRB%_avg10</th>\n",
       "      <th>gAST%_avg10</th>\n",
       "      <th>gSTL%_avg10</th>\n",
       "      <th>gBLK%_avg10</th>\n",
       "      <th>gDRtg_avg10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>201212090LAL</td>\n",
       "      <td>2012-12-09</td>\n",
       "      <td>6:30 pm</td>\n",
       "      <td>Los Angeles Lakers</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>227.0</td>\n",
       "      <td>207.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.5206</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.2981</td>\n",
       "      <td>69.22</td>\n",
       "      <td>50.05</td>\n",
       "      <td>61.57</td>\n",
       "      <td>8.63</td>\n",
       "      <td>10.31</td>\n",
       "      <td>110.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>201212100PHI</td>\n",
       "      <td>2012-12-10</td>\n",
       "      <td>7:00 pm</td>\n",
       "      <td>Philadelphia 76ers</td>\n",
       "      <td>Detroit Pistons</td>\n",
       "      <td>201.0</td>\n",
       "      <td>186.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>90.3</td>\n",
       "      <td>0.5077</td>\n",
       "      <td>0.2144</td>\n",
       "      <td>0.3095</td>\n",
       "      <td>71.46</td>\n",
       "      <td>49.48</td>\n",
       "      <td>59.83</td>\n",
       "      <td>6.48</td>\n",
       "      <td>9.46</td>\n",
       "      <td>107.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>201212100HOU</td>\n",
       "      <td>2012-12-10</td>\n",
       "      <td>7:00 pm</td>\n",
       "      <td>Houston Rockets</td>\n",
       "      <td>San Antonio Spurs</td>\n",
       "      <td>240.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.5915</td>\n",
       "      <td>0.2743</td>\n",
       "      <td>0.2518</td>\n",
       "      <td>74.26</td>\n",
       "      <td>50.99</td>\n",
       "      <td>61.82</td>\n",
       "      <td>8.30</td>\n",
       "      <td>6.85</td>\n",
       "      <td>101.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>201212110BRK</td>\n",
       "      <td>2012-12-11</td>\n",
       "      <td>7:00 pm</td>\n",
       "      <td>Brooklyn Nets</td>\n",
       "      <td>New York Knicks</td>\n",
       "      <td>197.0</td>\n",
       "      <td>195.5</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>100.3</td>\n",
       "      <td>0.5473</td>\n",
       "      <td>0.3595</td>\n",
       "      <td>0.2544</td>\n",
       "      <td>74.23</td>\n",
       "      <td>47.88</td>\n",
       "      <td>52.07</td>\n",
       "      <td>9.31</td>\n",
       "      <td>7.64</td>\n",
       "      <td>109.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>201212110DET</td>\n",
       "      <td>2012-12-11</td>\n",
       "      <td>7:30 pm</td>\n",
       "      <td>Detroit Pistons</td>\n",
       "      <td>Denver Nuggets</td>\n",
       "      <td>195.0</td>\n",
       "      <td>203.5</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>101.1</td>\n",
       "      <td>0.5605</td>\n",
       "      <td>0.2173</td>\n",
       "      <td>0.3177</td>\n",
       "      <td>68.45</td>\n",
       "      <td>50.40</td>\n",
       "      <td>56.33</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.83</td>\n",
       "      <td>114.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season        GameId    GameDate GameTime            HostName  \\\n",
       "0    2013  201212090LAL  2012-12-09  6:30 pm  Los Angeles Lakers   \n",
       "1    2013  201212100PHI  2012-12-10  7:00 pm  Philadelphia 76ers   \n",
       "2    2013  201212100HOU  2012-12-10  7:00 pm     Houston Rockets   \n",
       "3    2013  201212110BRK  2012-12-11  7:00 pm       Brooklyn Nets   \n",
       "4    2013  201212110DET  2012-12-11  7:30 pm     Detroit Pistons   \n",
       "\n",
       "           GuestName  total_score  total_line  game_line  Host_HostRank  ...  \\\n",
       "0          Utah Jazz        227.0       207.5        7.5             13  ...   \n",
       "1    Detroit Pistons        201.0       186.5        5.5             13  ...   \n",
       "2  San Antonio Spurs        240.0       212.0       -7.0             12  ...   \n",
       "3    New York Knicks        197.0       195.5       -3.5             12  ...   \n",
       "4     Denver Nuggets        195.0       203.5       -4.5             11  ...   \n",
       "\n",
       "   gPTS_avg10  gTS%_avg10  g3PAR_avg10  gFTr_avg10  gDRB%_avg10  gTRB%_avg10  \\\n",
       "0        99.0      0.5206       0.2230      0.2981        69.22        50.05   \n",
       "1        90.3      0.5077       0.2144      0.3095        71.46        49.48   \n",
       "2       108.0      0.5915       0.2743      0.2518        74.26        50.99   \n",
       "3       100.3      0.5473       0.3595      0.2544        74.23        47.88   \n",
       "4       101.1      0.5605       0.2173      0.3177        68.45        50.40   \n",
       "\n",
       "   gAST%_avg10  gSTL%_avg10 gBLK%_avg10 gDRtg_avg10  \n",
       "0        61.57         8.63       10.31      110.87  \n",
       "1        59.83         6.48        9.46      107.91  \n",
       "2        61.82         8.30        6.85      101.41  \n",
       "3        52.07         9.31        7.64      109.24  \n",
       "4        56.33         7.67        7.83      114.86  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the CSV file located in the current directory\n",
    "# The dataset contains aggregated basketball statistics for NBA seasons from 2013 to 2016\n",
    "data: pd.DataFrame = pd.read_csv('./basketball_data.csv')\n",
    "\n",
    "# Display the first five rows of the dataset to get an overview of the data structure and contents\n",
    "# This is useful for understanding the columns and the type of data we are working with\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Season', 'GameId', 'GameDate', 'GameTime', 'HostName', 'GuestName',\n",
      "       'total_score', 'total_line', 'game_line', 'Host_HostRank',\n",
      "       'Host_GameRank', 'Guest_GuestRank', 'Guest_GameRank', 'host_win_count',\n",
      "       'host_lose_count', 'guest_win_count', 'guest_lose_count', 'game_behind',\n",
      "       'winner', 'loser', 'host_place_streak', 'guest_place_streak',\n",
      "       'hq1_avg10', 'hq2_avg10', 'hq3_avg10', 'hq4_avg10', 'hPace_avg10',\n",
      "       'heFG%_avg10', 'hTOV%_avg10', 'hORB%_avg10', 'hFT/FGA_avg10',\n",
      "       'hORtg_avg10', 'hFG_avg10', 'hFGA_avg10', 'hFG%_avg10', 'h3P_avg10',\n",
      "       'h3PA_avg10', 'h3P%_avg10', 'hFT_avg10', 'hFTA_avg10', 'hFT%_avg10',\n",
      "       'hORB_avg10', 'hDRB_avg10', 'hTRB_avg10', 'hAST_avg10', 'hSTL_avg10',\n",
      "       'hBLK_avg10', 'hTOV_avg10', 'hPF_avg10', 'hPTS_avg10', 'hTS%_avg10',\n",
      "       'h3PAR_avg10', 'hFTr_avg10', 'hDRB%_avg10', 'hTRB%_avg10',\n",
      "       'hAST%_avg10', 'hSTL%_avg10', 'hBLK%_avg10', 'hDRtg_avg10', 'gq1_avg10',\n",
      "       'gq2_avg10', 'gq3_avg10', 'gq4_avg10', 'gPace_avg10', 'geFG%_avg10',\n",
      "       'gTOV%_avg10', 'gORB%_avg10', 'gFT/FGA_avg10', 'gORtg_avg10',\n",
      "       'gFG_avg10', 'gFGA_avg10', 'gFG%_avg10', 'g3P_avg10', 'g3PA_avg10',\n",
      "       'g3P%_avg10', 'gFT_avg10', 'gFTA_avg10', 'gFT%_avg10', 'gORB_avg10',\n",
      "       'gDRB_avg10', 'gTRB_avg10', 'gAST_avg10', 'gSTL_avg10', 'gBLK_avg10',\n",
      "       'gTOV_avg10', 'gPF_avg10', 'gPTS_avg10', 'gTS%_avg10', 'g3PAR_avg10',\n",
      "       'gFTr_avg10', 'gDRB%_avg10', 'gTRB%_avg10', 'gAST%_avg10',\n",
      "       'gSTL%_avg10', 'gBLK%_avg10', 'gDRtg_avg10'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Display all column names in the dataset\n",
    "# This is useful for understanding what features are available for analysis and modeling\n",
    "# The 'columns' attribute of a DataFrame returns an Index object containing column labels\n",
    "# Type annotation: 'Index' is the type for the column labels of a DataFrame\n",
    "\n",
    "columns: pd.Index = data.columns\n",
    "\n",
    "# Print the column names to inspect them\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 3768 rows and 96 columns.\n"
     ]
    }
   ],
   "source": [
    "# Display the shape of the dataset\n",
    "# The 'shape' attribute of a DataFrame returns a tuple representing the dimensions of the DataFrame\n",
    "# The first element of the tuple is the number of rows (i.e., the number of observations in the dataset)\n",
    "# The second element of the tuple is the number of columns (i.e., the number of features available for analysis)\n",
    "\n",
    "# Type annotation: The shape of a DataFrame is a tuple of two integers\n",
    "data_shape: tuple[int, int] = data.shape\n",
    "\n",
    "# Print the shape of the dataset to understand its dimensions\n",
    "# This helps in getting an immediate sense of the size of the data we are dealing with\n",
    "print(f\"The dataset contains {data_shape[0]} rows and {data_shape[1]} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2013 2014 2015 2016]\n"
     ]
    }
   ],
   "source": [
    "# Import the numpy library for numerical operations\n",
    "# 'np' is a commonly used alias for the numpy library\n",
    "import numpy as np\n",
    "\n",
    "# Display unique values in the 'Season' column\n",
    "# The 'unique' method returns the unique values in the specified column of the DataFrame\n",
    "# This is useful for understanding the different seasons represented in the dataset\n",
    "# For instance, it helps identify the range of years covered by the data\n",
    "\n",
    "# Type annotation:\n",
    "# - The 'Season' column is of type 'pd.Series', which represents a single column from the DataFrame\n",
    "# - The 'unique' method returns a 'np.ndarray' containing the unique values\n",
    "\n",
    "unique_seasons: np.ndarray = data.Season.unique()\n",
    "\n",
    "# Print the unique seasons to inspect them\n",
    "# This helps in verifying the time span of the dataset and ensuring it covers the intended seasons\n",
    "print(unique_seasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0             Utah Jazz\n",
      "1    Philadelphia 76ers\n",
      "2     San Antonio Spurs\n",
      "3       New York Knicks\n",
      "4        Denver Nuggets\n",
      "Name: winner, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Display the first five rows of the 'winner' column\n",
    "# The 'head' method returns the first n rows of the DataFrame or Series, by default it returns the first 5 rows\n",
    "# This is useful for quickly inspecting the initial values of a specific column\n",
    "# In this case, we are interested in the 'winner' column which indicates the winner of each game\n",
    "\n",
    "# Type annotation:\n",
    "# - 'data' is a DataFrame containing our dataset\n",
    "# - 'winner' is a Series object representing the 'winner' column in the DataFrame\n",
    "# - The 'head' method returns a Series object containing the first 5 rows of the 'winner' column\n",
    "\n",
    "winner_head: pd.Series = data.winner.head()\n",
    "\n",
    "# Print the first five rows of the 'winner' column to inspect the initial values\n",
    "# This helps in getting a quick overview of how the 'winner' data is structured and what kind of values it contains\n",
    "print(winner_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>GameId</th>\n",
       "      <th>GameDate</th>\n",
       "      <th>GameTime</th>\n",
       "      <th>HostName</th>\n",
       "      <th>GuestName</th>\n",
       "      <th>total_score</th>\n",
       "      <th>total_line</th>\n",
       "      <th>game_line</th>\n",
       "      <th>Host_HostRank</th>\n",
       "      <th>...</th>\n",
       "      <th>gTS%_avg10</th>\n",
       "      <th>g3PAR_avg10</th>\n",
       "      <th>gFTr_avg10</th>\n",
       "      <th>gDRB%_avg10</th>\n",
       "      <th>gTRB%_avg10</th>\n",
       "      <th>gAST%_avg10</th>\n",
       "      <th>gSTL%_avg10</th>\n",
       "      <th>gBLK%_avg10</th>\n",
       "      <th>gDRtg_avg10</th>\n",
       "      <th>host_wins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>201212090LAL</td>\n",
       "      <td>2012-12-09</td>\n",
       "      <td>6:30 pm</td>\n",
       "      <td>Los Angeles Lakers</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>227.0</td>\n",
       "      <td>207.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5206</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.2981</td>\n",
       "      <td>69.22</td>\n",
       "      <td>50.05</td>\n",
       "      <td>61.57</td>\n",
       "      <td>8.63</td>\n",
       "      <td>10.31</td>\n",
       "      <td>110.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>201212100PHI</td>\n",
       "      <td>2012-12-10</td>\n",
       "      <td>7:00 pm</td>\n",
       "      <td>Philadelphia 76ers</td>\n",
       "      <td>Detroit Pistons</td>\n",
       "      <td>201.0</td>\n",
       "      <td>186.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5077</td>\n",
       "      <td>0.2144</td>\n",
       "      <td>0.3095</td>\n",
       "      <td>71.46</td>\n",
       "      <td>49.48</td>\n",
       "      <td>59.83</td>\n",
       "      <td>6.48</td>\n",
       "      <td>9.46</td>\n",
       "      <td>107.91</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>201212100HOU</td>\n",
       "      <td>2012-12-10</td>\n",
       "      <td>7:00 pm</td>\n",
       "      <td>Houston Rockets</td>\n",
       "      <td>San Antonio Spurs</td>\n",
       "      <td>240.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5915</td>\n",
       "      <td>0.2743</td>\n",
       "      <td>0.2518</td>\n",
       "      <td>74.26</td>\n",
       "      <td>50.99</td>\n",
       "      <td>61.82</td>\n",
       "      <td>8.30</td>\n",
       "      <td>6.85</td>\n",
       "      <td>101.41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>201212110BRK</td>\n",
       "      <td>2012-12-11</td>\n",
       "      <td>7:00 pm</td>\n",
       "      <td>Brooklyn Nets</td>\n",
       "      <td>New York Knicks</td>\n",
       "      <td>197.0</td>\n",
       "      <td>195.5</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5473</td>\n",
       "      <td>0.3595</td>\n",
       "      <td>0.2544</td>\n",
       "      <td>74.23</td>\n",
       "      <td>47.88</td>\n",
       "      <td>52.07</td>\n",
       "      <td>9.31</td>\n",
       "      <td>7.64</td>\n",
       "      <td>109.24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>201212110DET</td>\n",
       "      <td>2012-12-11</td>\n",
       "      <td>7:30 pm</td>\n",
       "      <td>Detroit Pistons</td>\n",
       "      <td>Denver Nuggets</td>\n",
       "      <td>195.0</td>\n",
       "      <td>203.5</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5605</td>\n",
       "      <td>0.2173</td>\n",
       "      <td>0.3177</td>\n",
       "      <td>68.45</td>\n",
       "      <td>50.40</td>\n",
       "      <td>56.33</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.83</td>\n",
       "      <td>114.86</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season        GameId    GameDate GameTime            HostName  \\\n",
       "0    2013  201212090LAL  2012-12-09  6:30 pm  Los Angeles Lakers   \n",
       "1    2013  201212100PHI  2012-12-10  7:00 pm  Philadelphia 76ers   \n",
       "2    2013  201212100HOU  2012-12-10  7:00 pm     Houston Rockets   \n",
       "3    2013  201212110BRK  2012-12-11  7:00 pm       Brooklyn Nets   \n",
       "4    2013  201212110DET  2012-12-11  7:30 pm     Detroit Pistons   \n",
       "\n",
       "           GuestName  total_score  total_line  game_line  Host_HostRank  ...  \\\n",
       "0          Utah Jazz        227.0       207.5        7.5             13  ...   \n",
       "1    Detroit Pistons        201.0       186.5        5.5             13  ...   \n",
       "2  San Antonio Spurs        240.0       212.0       -7.0             12  ...   \n",
       "3    New York Knicks        197.0       195.5       -3.5             12  ...   \n",
       "4     Denver Nuggets        195.0       203.5       -4.5             11  ...   \n",
       "\n",
       "   gTS%_avg10  g3PAR_avg10  gFTr_avg10  gDRB%_avg10  gTRB%_avg10  gAST%_avg10  \\\n",
       "0      0.5206       0.2230      0.2981        69.22        50.05        61.57   \n",
       "1      0.5077       0.2144      0.3095        71.46        49.48        59.83   \n",
       "2      0.5915       0.2743      0.2518        74.26        50.99        61.82   \n",
       "3      0.5473       0.3595      0.2544        74.23        47.88        52.07   \n",
       "4      0.5605       0.2173      0.3177        68.45        50.40        56.33   \n",
       "\n",
       "   gSTL%_avg10  gBLK%_avg10 gDRtg_avg10 host_wins  \n",
       "0         8.63        10.31      110.87         0  \n",
       "1         6.48         9.46      107.91         1  \n",
       "2         8.30         6.85      101.41         0  \n",
       "3         9.31         7.64      109.24         0  \n",
       "4         7.67         7.83      114.86         0  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a binary integer column to represent whether the host team won or lost\n",
    "# This new column will be named 'host_wins'\n",
    "# The column is created based on a comparison between the 'HostName' and 'winner' columns\n",
    "# If the 'HostName' matches the 'winner', it indicates the host team won the game\n",
    "# - In this case, we assign a value of 1 (indicating a win)\n",
    "# Otherwise, it indicates the host team lost the game\n",
    "# - In this case, we assign a value of 0 (indicating a loss)\n",
    "\n",
    "# Type annotation:\n",
    "# - 'data' is a DataFrame containing our dataset\n",
    "# - 'HostName' and 'winner' are Series objects representing the respective columns in the DataFrame\n",
    "# - The comparison operation (data.HostName == data.winner) results in a Series of boolean values (True/False)\n",
    "# - The 'astype(int)' method converts the boolean values to integers (1 for True, 0 for False)\n",
    "# - The resulting Series is assigned to a new column 'host_wins' in the DataFrame\n",
    "\n",
    "data['host_wins'] = (data.HostName == data.winner).astype(int)\n",
    "\n",
    "# Display the first five rows of the updated DataFrame to verify the new 'host_wins' column\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Host_HostRank</th>\n",
       "      <th>Host_GameRank</th>\n",
       "      <th>Guest_GuestRank</th>\n",
       "      <th>Guest_GameRank</th>\n",
       "      <th>host_win_count</th>\n",
       "      <th>host_lose_count</th>\n",
       "      <th>guest_win_count</th>\n",
       "      <th>guest_lose_count</th>\n",
       "      <th>game_behind</th>\n",
       "      <th>host_place_streak</th>\n",
       "      <th>...</th>\n",
       "      <th>gPTS_avg10</th>\n",
       "      <th>gTS%_avg10</th>\n",
       "      <th>g3PAR_avg10</th>\n",
       "      <th>gFTr_avg10</th>\n",
       "      <th>gDRB%_avg10</th>\n",
       "      <th>gTRB%_avg10</th>\n",
       "      <th>gAST%_avg10</th>\n",
       "      <th>gSTL%_avg10</th>\n",
       "      <th>gBLK%_avg10</th>\n",
       "      <th>gDRtg_avg10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.5206</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.2981</td>\n",
       "      <td>69.22</td>\n",
       "      <td>50.05</td>\n",
       "      <td>61.57</td>\n",
       "      <td>8.63</td>\n",
       "      <td>10.31</td>\n",
       "      <td>110.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>90.3</td>\n",
       "      <td>0.5077</td>\n",
       "      <td>0.2144</td>\n",
       "      <td>0.3095</td>\n",
       "      <td>71.46</td>\n",
       "      <td>49.48</td>\n",
       "      <td>59.83</td>\n",
       "      <td>6.48</td>\n",
       "      <td>9.46</td>\n",
       "      <td>107.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.5915</td>\n",
       "      <td>0.2743</td>\n",
       "      <td>0.2518</td>\n",
       "      <td>74.26</td>\n",
       "      <td>50.99</td>\n",
       "      <td>61.82</td>\n",
       "      <td>8.30</td>\n",
       "      <td>6.85</td>\n",
       "      <td>101.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>100.3</td>\n",
       "      <td>0.5473</td>\n",
       "      <td>0.3595</td>\n",
       "      <td>0.2544</td>\n",
       "      <td>74.23</td>\n",
       "      <td>47.88</td>\n",
       "      <td>52.07</td>\n",
       "      <td>9.31</td>\n",
       "      <td>7.64</td>\n",
       "      <td>109.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>101.1</td>\n",
       "      <td>0.5605</td>\n",
       "      <td>0.2173</td>\n",
       "      <td>0.3177</td>\n",
       "      <td>68.45</td>\n",
       "      <td>50.40</td>\n",
       "      <td>56.33</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.83</td>\n",
       "      <td>114.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3763</th>\n",
       "      <td>49</td>\n",
       "      <td>99</td>\n",
       "      <td>49</td>\n",
       "      <td>102</td>\n",
       "      <td>69</td>\n",
       "      <td>29</td>\n",
       "      <td>87</td>\n",
       "      <td>14</td>\n",
       "      <td>-16.5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>105.9</td>\n",
       "      <td>0.5499</td>\n",
       "      <td>0.3908</td>\n",
       "      <td>0.2580</td>\n",
       "      <td>70.42</td>\n",
       "      <td>46.46</td>\n",
       "      <td>58.45</td>\n",
       "      <td>7.89</td>\n",
       "      <td>8.15</td>\n",
       "      <td>106.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3764</th>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>103</td>\n",
       "      <td>70</td>\n",
       "      <td>29</td>\n",
       "      <td>87</td>\n",
       "      <td>15</td>\n",
       "      <td>-15.5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>104.6</td>\n",
       "      <td>0.5483</td>\n",
       "      <td>0.3949</td>\n",
       "      <td>0.2720</td>\n",
       "      <td>69.29</td>\n",
       "      <td>45.67</td>\n",
       "      <td>60.14</td>\n",
       "      <td>7.83</td>\n",
       "      <td>7.76</td>\n",
       "      <td>110.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3765</th>\n",
       "      <td>54</td>\n",
       "      <td>104</td>\n",
       "      <td>51</td>\n",
       "      <td>101</td>\n",
       "      <td>88</td>\n",
       "      <td>15</td>\n",
       "      <td>70</td>\n",
       "      <td>30</td>\n",
       "      <td>16.5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>98.6</td>\n",
       "      <td>0.5483</td>\n",
       "      <td>0.4116</td>\n",
       "      <td>0.2206</td>\n",
       "      <td>77.65</td>\n",
       "      <td>51.65</td>\n",
       "      <td>56.93</td>\n",
       "      <td>7.70</td>\n",
       "      <td>7.02</td>\n",
       "      <td>113.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3766</th>\n",
       "      <td>51</td>\n",
       "      <td>102</td>\n",
       "      <td>51</td>\n",
       "      <td>105</td>\n",
       "      <td>71</td>\n",
       "      <td>30</td>\n",
       "      <td>88</td>\n",
       "      <td>16</td>\n",
       "      <td>-15.5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>105.4</td>\n",
       "      <td>0.5515</td>\n",
       "      <td>0.3979</td>\n",
       "      <td>0.2954</td>\n",
       "      <td>68.66</td>\n",
       "      <td>46.14</td>\n",
       "      <td>61.98</td>\n",
       "      <td>8.34</td>\n",
       "      <td>7.90</td>\n",
       "      <td>111.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3767</th>\n",
       "      <td>55</td>\n",
       "      <td>106</td>\n",
       "      <td>52</td>\n",
       "      <td>103</td>\n",
       "      <td>88</td>\n",
       "      <td>17</td>\n",
       "      <td>72</td>\n",
       "      <td>30</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>99.6</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>0.3923</td>\n",
       "      <td>0.2266</td>\n",
       "      <td>77.84</td>\n",
       "      <td>51.70</td>\n",
       "      <td>53.67</td>\n",
       "      <td>8.27</td>\n",
       "      <td>8.25</td>\n",
       "      <td>111.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3768 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Host_HostRank  Host_GameRank  Guest_GuestRank  Guest_GameRank  \\\n",
       "0                13             21               13              22   \n",
       "1                13             21               13              23   \n",
       "2                12             20               13              22   \n",
       "3                12             20               13              21   \n",
       "4                11             24               16              22   \n",
       "...             ...            ...              ...             ...   \n",
       "3763             49             99               49             102   \n",
       "3764             50            100               50             103   \n",
       "3765             54            104               51             101   \n",
       "3766             51            102               51             105   \n",
       "3767             55            106               52             103   \n",
       "\n",
       "      host_win_count  host_lose_count  guest_win_count  guest_lose_count  \\\n",
       "0                  9               11               11                10   \n",
       "1                 11                9                7                15   \n",
       "2                  9               10               17                 4   \n",
       "3                 11                8               15                 5   \n",
       "4                  7               16               10                11   \n",
       "...              ...              ...              ...               ...   \n",
       "3763              69               29               87                14   \n",
       "3764              70               29               87                15   \n",
       "3765              88               15               70                30   \n",
       "3766              71               30               88                16   \n",
       "3767              88               17               72                30   \n",
       "\n",
       "      game_behind  host_place_streak  ...  gPTS_avg10  gTS%_avg10  \\\n",
       "0            -1.5                  1  ...        99.0      0.5206   \n",
       "1             5.0                  1  ...        90.3      0.5077   \n",
       "2            -7.0                  2  ...       108.0      0.5915   \n",
       "3            -3.5                  4  ...       100.3      0.5473   \n",
       "4            -4.0                  1  ...       101.1      0.5605   \n",
       "...           ...                ...  ...         ...         ...   \n",
       "3763        -16.5                  1  ...       105.9      0.5499   \n",
       "3764        -15.5                  2  ...       104.6      0.5483   \n",
       "3765         16.5                  1  ...        98.6      0.5483   \n",
       "3766        -15.5                  1  ...       105.4      0.5515   \n",
       "3767         14.5                  1  ...        99.6      0.5523   \n",
       "\n",
       "      g3PAR_avg10  gFTr_avg10  gDRB%_avg10  gTRB%_avg10  gAST%_avg10  \\\n",
       "0          0.2230      0.2981        69.22        50.05        61.57   \n",
       "1          0.2144      0.3095        71.46        49.48        59.83   \n",
       "2          0.2743      0.2518        74.26        50.99        61.82   \n",
       "3          0.3595      0.2544        74.23        47.88        52.07   \n",
       "4          0.2173      0.3177        68.45        50.40        56.33   \n",
       "...           ...         ...          ...          ...          ...   \n",
       "3763       0.3908      0.2580        70.42        46.46        58.45   \n",
       "3764       0.3949      0.2720        69.29        45.67        60.14   \n",
       "3765       0.4116      0.2206        77.65        51.65        56.93   \n",
       "3766       0.3979      0.2954        68.66        46.14        61.98   \n",
       "3767       0.3923      0.2266        77.84        51.70        53.67   \n",
       "\n",
       "      gSTL%_avg10  gBLK%_avg10  gDRtg_avg10  \n",
       "0            8.63        10.31       110.87  \n",
       "1            6.48         9.46       107.91  \n",
       "2            8.30         6.85       101.41  \n",
       "3            9.31         7.64       109.24  \n",
       "4            7.67         7.83       114.86  \n",
       "...           ...          ...          ...  \n",
       "3763         7.89         8.15       106.99  \n",
       "3764         7.83         7.76       110.42  \n",
       "3765         7.70         7.02       113.52  \n",
       "3766         8.34         7.90       111.31  \n",
       "3767         8.27         8.25       111.97  \n",
       "\n",
       "[3768 rows x 85 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract predictor columns for the model\n",
    "# We need to exclude specific columns that do not contribute to statistical modeling\n",
    "# Specifically, we exclude columns related to game metadata and outcome\n",
    "# These columns include identifiers and labels which should not be used as predictors\n",
    "\n",
    "# Type annotation:\n",
    "# - 'columns' is a pd.Index object containing all column labels in the DataFrame\n",
    "# - 'predictors': list[str] is a list of strings representing the names of columns to be used as predictors\n",
    "\n",
    "predictors: list[str] = [each_column for each_column in columns if each_column not in [\n",
    "    'GameId', 'GameDate', 'GameTime', 'HostName', 'GuestName', 'total_score', 'total_line', 'game_line',\n",
    "    'winner', 'loser', 'host_wins', 'Season'\n",
    "]]\n",
    "\n",
    "# Create the predictor matrix 'X'\n",
    "# 'data[predictors]' selects the columns specified in the 'predictors' list from the DataFrame\n",
    "# The resulting DataFrame 'X' contains only the predictor variables\n",
    "\n",
    "# Type annotation:\n",
    "# - 'X': pd.DataFrame is a DataFrame containing the predictor variables\n",
    "\n",
    "X: pd.DataFrame = data[predictors]\n",
    "\n",
    "# Create the target vector 'y'\n",
    "# 'data.host_wins' selects the 'host_wins' column from the DataFrame\n",
    "# The 'values' attribute returns the underlying numpy array of the Series, representing the target vector\n",
    "\n",
    "# Type annotation:\n",
    "# - 'y': np.ndarray is a numpy array containing the target values (binary outcomes indicating host team wins)\n",
    "\n",
    "y: np.ndarray = data.host_wins.values\n",
    "\n",
    "# Display the first five rows of the predictor matrix 'X'\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target vector 'y' contains 3768 elements.\n"
     ]
    }
   ],
   "source": [
    "# Display the shape of the target vector 'y'\n",
    "# The 'shape' attribute of a numpy array returns a tuple representing the dimensions of the array\n",
    "# For a 1-dimensional array (such as our target vector 'y'), the tuple will contain a single integer\n",
    "# This integer represents the number of elements (i.e., the number of observations in the dataset)\n",
    "\n",
    "# Type annotation:\n",
    "# - 'y' is a numpy array (np.ndarray) containing the target values\n",
    "# - The shape of a 1-dimensional numpy array is a tuple with a single integer element\n",
    "\n",
    "y_shape: tuple[int] = y.shape\n",
    "\n",
    "# Print the shape of the target vector to understand its dimensions\n",
    "# This helps in confirming the number of target values and ensuring it matches the number of observations in the predictor matrix 'X'\n",
    "print(f\"The target vector 'y' contains {y_shape[0]} elements.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Training and Testing Data\n",
    "\n",
    "To effectively evaluate our model, we need to divide our dataset into training and testing sets. The testing set will be composed of data from the 2016 season, while the training set will include data from the previous seasons.\n",
    "\n",
    "Before splitting the data into these sets, it's crucial to standardize our predictor matrix. Standardization ensures that all the predictor variables have a mean of zero and a standard deviation of one, which helps improve the performance of many machine learning algorithms. Standardizing the predictor matrix before splitting the data ensures that both the training and testing sets are scaled consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_columns = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.56994302 -1.80361737 -1.57694346 -1.75692321 -1.2982167  -1.26254621\n",
      "  -1.17988804 -1.35352853 -0.11596441 -0.74662381 -0.74082975  1.71239604\n",
      "  -0.06199287 -0.46189658 -0.8305345   0.08262642 -0.08558553  0.40546099\n",
      "   1.85754177  0.6057853   0.14916416 -0.41641343 -0.44683582 -0.21242025\n",
      "   0.1992716   0.29615239 -0.09289878  0.60822405  1.86012793 -2.17630576\n",
      "   1.68166747  0.65581588  1.59077716  0.11925515  0.09563853  0.73232279\n",
      "   0.53022972 -1.45547259  0.02394679 -0.25781958  0.41122333  1.81194444\n",
      "  -0.27982338  1.35802031  0.35675453  0.15106925  0.41305079 -1.45332279\n",
      "  -0.54316291 -1.32562743  0.28857155  0.14247962 -0.97307291 -0.63405092\n",
      "   0.76585642  2.07344245  0.51376123  0.04727851 -0.27289994  0.28059216\n",
      "  -0.62832368 -0.22730199 -0.74535003  1.12786279  0.4841132   0.49303332\n",
      "   0.16828885  2.31538702 -1.26136331  0.41168218  0.38667978  0.21355929\n",
      "   2.30653791  1.00156513  0.24936795 -0.06329992 -0.5328119  -0.85019243\n",
      "   0.54033761 -1.81614105  0.30302014  0.83074192  0.32912129  1.66268587\n",
      "   0.57743326]\n",
      " [-1.56994302 -1.80361737 -1.57694346 -1.70591668 -1.1680669  -1.42563691\n",
      "  -1.44225559 -0.9422902   0.39763421 -0.74662381  0.03825105 -0.96974513\n",
      "  -0.94293641 -0.32504192 -1.0646629  -0.85106581 -1.07280842 -1.65322723\n",
      "  -0.64292488 -0.98276463 -0.98186961 -0.68490943  0.5117564  -1.09183584\n",
      "  -0.42315619 -0.79095263  0.52692454 -0.93175427 -0.73333892 -0.3150609\n",
      "  -0.22329546 -1.24647127 -1.15536251  0.00363115  0.39872179 -0.0785477\n",
      "  -1.6730186   0.25889887 -1.06905486 -1.2500306  -0.87450043 -0.80136166\n",
      "  -0.54214729 -1.83969692  0.50038286  0.47551286 -0.18931391  0.14815693\n",
      "  -0.91221741 -0.45209259 -1.96122738 -0.65993151 -0.79035436 -1.2343244\n",
      "   1.4973662   0.78949916  0.72803705 -1.30478544 -1.95585731 -1.38652066\n",
      "  -1.12054624 -0.95084983 -1.17951101  0.52312769  0.36506742  0.43218235\n",
      "  -0.16080988  0.53557968 -0.17718383  0.18925869 -0.67968475 -1.40724637\n",
      "   1.0666102   1.19584223 -0.57981383 -1.61498818 -1.05226432 -1.01151955\n",
      "   0.80370147 -1.06909673  0.04909328  0.45729587 -1.29605314  1.13761889\n",
      "  -0.09605319]\n",
      " [-1.67145214 -1.85452053 -1.57694346 -1.75692321 -1.2982167  -1.34409156\n",
      "  -0.78633672 -1.84701453 -0.55054786  0.05855035  0.03825105 -0.74989749\n",
      "   2.39537595  0.99788644  0.15280483  0.85625712  0.36078257  0.67899299\n",
      "   0.11604678  1.35900148  0.60774345 -0.23741611 -0.14727575 -0.1447729\n",
      "   1.18478227  1.3610716   0.44025433  1.47211433  1.30017486  0.51141245\n",
      "   0.05684614 -0.38179529 -0.27518954  0.00363115  0.4744926  -0.40289589\n",
      "   0.84497948 -0.11611989  0.86471729  0.65859755  1.47218353  1.22312357\n",
      "  -1.04493478 -0.13695766  0.22245272  0.37965452 -0.53723145  0.05651913\n",
      "   0.93305508 -0.77392121  1.36456235  1.99805535  0.10293634  2.4211872\n",
      "   0.75846743 -0.73500235 -0.20753345  1.57961766  2.0351559  -0.12887415\n",
      "   2.67864732  0.59960982  0.1012639   0.9530999  -0.38888921 -0.72398599\n",
      "   0.64615823 -1.54086223  1.13286636 -0.03316479  1.85293101  0.05919685\n",
      "   0.20819871  0.61301093 -1.46081948  1.54189483  2.32216299  0.11214258\n",
      "  -0.52928931 -0.13529132  0.72177672  0.88439796  0.07967592 -0.4746456\n",
      "  -1.57499305]\n",
      " [-1.67145214 -1.85452053 -1.57694346 -1.80792974 -1.1680669  -1.50718226\n",
      "  -0.91752049 -1.76476686 -0.27399476  1.66889867 -0.74082975  0.96491408\n",
      "  -1.26749456 -1.28302452 -0.8305345  -1.86145418 -0.65576377  0.10313614\n",
      "   1.96241785 -0.23238008  0.26477239 -0.99815475 -0.20718776 -0.90083155\n",
      "   0.1992716   0.42926729 -0.32139297 -0.25566623 -0.14391463 -0.45392634\n",
      "   1.68166747 -1.54910786 -0.2047757  -0.11199285 -0.88938204  0.57014869\n",
      "  -0.03631985 -0.65186097 -0.8000083  -0.69880225  0.46455706 -0.11991729\n",
      "  -1.52950533  0.23791597  0.5880521  -0.58630259  0.36631559  0.43616146\n",
      "   0.84079145  0.19156466  0.04402819 -0.55963012 -1.01706071  0.63575838\n",
      "  -1.18483634 -0.24229274 -0.4097374   0.93607714 -0.41715343 -0.12887415\n",
      "  -0.34159209  2.04670549  1.68595151  1.09457462 -0.50793499 -0.54143309\n",
      "  -0.03908843 -0.17634326 -0.94514429 -0.88578815 -1.12400331  0.59946541\n",
      "   0.0174406  -1.3945191  -0.2170468   0.16856154  0.54233379  1.71040657\n",
      "  -0.46922387 -0.14529638 -0.66368387 -1.20818769  0.84312995  0.01335783\n",
      "   0.20656065]\n",
      " [-1.77296125 -1.65090788 -1.27061667 -1.75692321 -1.42836651 -0.85481947\n",
      "  -1.24547993 -1.27128087 -0.31350235 -0.74662381  1.59641264 -0.48608032\n",
      "   0.44802707 -0.87246055  0.34010755 -1.0478081   0.40639683  0.19671288\n",
      "   0.28992029  0.75019892  0.43047751 -0.28216544 -1.49529607  0.86197889\n",
      "  -0.993715   -1.61182786  1.27018725  0.38286137  0.82863543 -0.9645928\n",
      "  -0.16726714 -1.41940647 -1.26098326 -0.4974062  -0.51052798 -0.32180885\n",
      "  -0.0992698   0.58034352 -0.36280764  0.38298338 -1.44593321  1.16799053\n",
      "  -1.70074455 -0.64281123 -0.4248074  -0.29872757 -0.46453226 -0.02857312\n",
      "  -0.1279766   1.93863433 -0.64069323 -0.05812317 -0.22528032  1.19755279\n",
      "   1.77075874  1.69086793  0.57412062  0.73483972  0.592621   -1.15253991\n",
      "   1.84712571 -0.79580386 -1.09267882  0.35391283  0.32538549  0.73643718\n",
      "  -0.95199927  0.6542335  -1.12584087 -0.51508234  0.07565679 -0.4810717\n",
      "   0.30357776  1.64915547 -0.06157522  0.31124552  1.07386649 -0.95711854\n",
      "   0.99313863 -2.07293753  0.45894014 -0.29388873 -0.39653799  0.13072574\n",
      "   1.48527481]]\n"
     ]
    }
   ],
   "source": [
    "# Import the StandardScaler class from the sklearn.preprocessing module\n",
    "# StandardScaler is used for standardizing features by removing the mean and scaling to unit variance\n",
    "# Type annotation: 'StandardScaler' is a class that will be instantiated and used for feature scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Instantiate the StandardScaler\n",
    "# 'ss' is an instance of the StandardScaler class\n",
    "# This scaler will be used to fit and transform the predictor matrix 'X'\n",
    "# Type annotation: 'ss' is an instance of the 'StandardScaler' class\n",
    "\n",
    "ss: StandardScaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler to the predictor matrix 'X' and transform the data\n",
    "# The 'fit_transform' method first fits the scaler to the data (computes the mean and standard deviation)\n",
    "# Then, it transforms the data by standardizing it (subtracting the mean and dividing by the standard deviation)\n",
    "# The transformed data is returned as a numpy array with standardized features\n",
    "# Type annotation:\n",
    "# - 'X' is a pd.DataFrame containing the predictor variables\n",
    "# - The result of 'ss.fit_transform(X)' is a numpy array (np.ndarray) with the same shape as 'X'\n",
    "\n",
    "X: np.ndarray = ss.fit_transform(X)\n",
    "\n",
    "# Display the first five rows of the standardized predictor matrix to verify the transformation\n",
    "print(X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2783, 85)\n",
      "X_test shape: (985, 85)\n",
      "y_train shape: (2783,)\n",
      "y_test shape: (985,)\n"
     ]
    }
   ],
   "source": [
    "# Split the standardized predictor matrix 'X' into training and testing sets\n",
    "# The training set will contain data from the 2013, 2014, and 2015 seasons\n",
    "# The testing set will contain data from the 2016 season\n",
    "\n",
    "# Type annotation:\n",
    "# - 'data': pd.DataFrame is the original dataset containing all columns including 'Season' and 'host_wins'\n",
    "# - 'X': np.ndarray is the standardized predictor matrix containing the predictor variables\n",
    "\n",
    "# Create the training predictor matrix 'X_train'\n",
    "# 'data.Season.isin([2013, 2014, 2015])' creates a boolean mask identifying rows corresponding to the specified seasons\n",
    "# Using this mask, we select the corresponding rows from the standardized predictor matrix 'X'\n",
    "# The resulting 'X_train' is a numpy array containing the training set predictor variables\n",
    "\n",
    "X_train: np.ndarray = X[data.Season.isin([2013, 2014, 2015])]\n",
    "\n",
    "# Create the testing predictor matrix 'X_test'\n",
    "# 'data.Season == 2016' creates a boolean mask identifying rows corresponding to the 2016 season\n",
    "# Using this mask, we select the corresponding rows from the standardized predictor matrix 'X'\n",
    "# The resulting 'X_test' is a numpy array containing the testing set predictor variables\n",
    "\n",
    "X_test: np.ndarray = X[data.Season == 2016]\n",
    "\n",
    "# Ensure the target vector 'y' is in an acceptable array format for the training and testing sets\n",
    "# The 'np.ravel' function flattens the input array into a 1-dimensional array\n",
    "# This ensures the target vectors 'y_train' and 'y_test' are in the correct format for model training and evaluation\n",
    "\n",
    "# Create the training target vector 'y_train'\n",
    "# We use the same boolean mask as for 'X_train' to select the corresponding rows from the target vector 'y'\n",
    "# 'np.ravel' flattens the resulting array into a 1-dimensional array\n",
    "\n",
    "y_train: np.ndarray = np.ravel(y[data.Season.isin([2013, 2014, 2015])])\n",
    "\n",
    "# Create the testing target vector 'y_test'\n",
    "# We use the same boolean mask as for 'X_test' to select the corresponding rows from the target vector 'y'\n",
    "# 'np.ravel' flattens the resulting array into a 1-dimensional array\n",
    "\n",
    "y_test: np.ndarray = np.ravel(y[data.Season == 2016])\n",
    "\n",
    "# Display the shapes of the training and testing sets to verify the split\n",
    "# This helps in confirming that the training and testing sets have the expected number of observations\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the Default KNN Model\n",
    "\n",
    "In the following section, we will fit a `KNeighborsClassifier` with its default settings to our training data to predict whether the home team wins or not. After fitting the model, we will evaluate its performance by scoring it on our testing data.\n",
    "\n",
    "It is essential to compare the model's accuracy to the baseline accuracy to understand how well the model is performing relative to the simplest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the KNeighborsClassifier class from the sklearn.neighbors module\n",
    "# KNeighborsClassifier is used for classification based on the k-nearest neighbors algorithm\n",
    "# Type annotation: 'KNeighborsClassifier' is a class that will be instantiated and used for classification\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Instantiate the KNeighborsClassifier with default parameters\n",
    "# 'knn' is an instance of the KNeighborsClassifier class\n",
    "# This classifier will be used to fit the training data and make predictions\n",
    "# Type annotation: 'knn' is an instance of the 'KNeighborsClassifier' class\n",
    "\n",
    "knn: KNeighborsClassifier = KNeighborsClassifier()\n",
    "\n",
    "# Fit the KNeighborsClassifier to the training data\n",
    "# The 'fit' method trains the classifier using the provided predictor matrix 'X_train' and target vector 'y_train'\n",
    "# After fitting, the classifier can be used to make predictions on new data\n",
    "# Type annotations:\n",
    "# - 'X_train': np.ndarray is the predictor matrix containing the training set predictor variables\n",
    "# - 'y_train': np.ndarray is the target vector containing the training set target values (binary outcomes)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# After fitting the model, 'knn' now contains the trained K-Nearest Neighbors classifier\n",
    "# It can be used to make predictions and evaluate model performance on the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on the test set: 0.57\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance of the fitted KNeighborsClassifier on the testing data\n",
    "# The 'score' method computes the accuracy of the classifier on the provided test data and labels\n",
    "# Accuracy is defined as the ratio of correctly predicted observations to the total observations\n",
    "# Type annotations:\n",
    "# - 'knn': KNeighborsClassifier is the fitted K-Nearest Neighbors classifier instance\n",
    "# - 'X_test': np.ndarray is the predictor matrix containing the testing set predictor variables\n",
    "# - 'y_test': np.ndarray is the target vector containing the testing set target values (binary outcomes)\n",
    "# - The result of 'knn.score(X_test, y_test)' is a float representing the accuracy of the model on the test set\n",
    "\n",
    "accuracy: float = knn.score(X_test, y_test)\n",
    "\n",
    "# Print the accuracy to understand how well the model performs on the testing data\n",
    "# This helps in comparing the model's performance against the baseline and other models\n",
    "print(f\"Model accuracy on the test set: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy (proportion of home team wins in the test set): 0.60\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean of the target vector 'y_test'\n",
    "# The target vector 'y_test' contains the binary outcomes indicating whether the home team wins (1) or loses (0) for each game in the test set\n",
    "# By taking the mean of 'y_test', we are calculating the proportion of games in the test set where the home team wins\n",
    "# This proportion can be interpreted as the baseline accuracy for a simple model that always predicts the home team will win\n",
    "\n",
    "# Type annotations:\n",
    "# - 'y_test': np.ndarray is a numpy array containing the binary target values for the test set\n",
    "# - The result of 'np.mean(y_test)' is a float representing the mean of the target vector, i.e., the proportion of home team wins\n",
    "\n",
    "baseline_accuracy: float = np.mean(y_test)\n",
    "\n",
    "# Print the mean of the target vector 'y_test' to understand the baseline accuracy\n",
    "# This helps in comparing the performance of our K-Nearest Neighbors model against the simplest model that always predicts a home team win\n",
    "print(f\"Baseline accuracy (proportion of home team wins in the test set): {baseline_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching for the Best Hyperparameters\n",
    "\n",
    "Our default KNN model performs poorly on the test data. This prompts the question: what if we adjusted some of the hyperparameters like the number of neighbors, the weighting scheme, or the distance metric?\n",
    "\n",
    "These components—number of neighbors, weighting, and distance metric—are all hyperparameters of the KNN algorithm. Manually searching for the best hyperparameters involves evaluating different combinations of these settings on the training data to find the set that yields the best performance. Once identified, this optimal set of hyperparameters is then used to fit the final model, which is subsequently evaluated on the testing data.\n",
    "\n",
    "### Grid Search Pseudocode for our KNN\n",
    "\n",
    "```python\n",
    "accuracies = {}\n",
    "for k in neighbors_to_test:\n",
    "    for w in weightings_to_test:\n",
    "        for d in distance_metrics_to_test:\n",
    "            hyperparam_set = (k, w, d)\n",
    "            knn = KNeighborsClassifier(n_neighbors=k, weights=w, metric=d)\n",
    "            cv_accuracies = cross_val_score(knn, X_train, y_train, cv=5)\n",
    "            accuracies[hyperparam_set] = np.mean(cv_accuracies)\n",
    "\n",
    "```\n",
    "\n",
    "In this pseudocode, we iterate over all possible combinations of hyperparameters: the number of neighbors (`k`), weightings (`w`), and distance metrics (`d`). For each combination, we create a KNN model and evaluate its performance using cross-validation on the training data. We store the mean cross-validated accuracy for each hyperparameter set in a dictionary. After running the grid search, we would identify the hyperparameter set (the key in the dictionary) that has the highest mean accuracy.\n",
    "\n",
    "### Using `GridSearchCV`\n",
    "\n",
    "Manually searching for the best combination of hyperparameters can be quite tedious and time-consuming. Fortunately, `scikit-learn` simplifies this process by providing a convenient class called `GridSearchCV` that automates grid searching.\n",
    "\n",
    "To start using `GridSearchCV`, you need to import it from the `sklearn.model_selection` module:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "```\n",
    "\n",
    "`GridSearchCV` includes several crucial arguments that you need to specify:\n",
    "\n",
    "| Argument | Description |\n",
    "| --- | --- |\n",
    "| estimator | The scikit-learn model instance to fit. |\n",
    "| param_grid | A dictionary where the keys are the model's hyperparameters and the values are lists of parameter settings to try. |\n",
    "| cv | The number of cross-validation folds to use for each hyperparameter combination. |\n",
    "| n_jobs | Number of CPU cores to use while running the folds. Setting this to -1 utilizes all available cores. |\n",
    "| verbose | Level of verbosity. 0 is silent, 1 provides limited output, and 2 prints detailed information for every internal fit. |\n",
    "\n",
    "Here’s an example of how you might set up `GridSearchCV` to find the best hyperparameters for our KNN model:\n",
    "\n",
    "```python\n",
    "knn_parameters = {\n",
    "    'n_neighbors': [1, 3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "knn_gridsearcher = GridSearchCV(KNeighborsClassifier(), knn_parameters, cv=5, verbose=1)\n",
    "knn_gridsearcher.fit(X_train, y_train)\n",
    "\n",
    "```\n",
    "\n",
    "In this example, `knn_parameters` is a dictionary specifying the hyperparameters to test: different values for the number of neighbors (`n_neighbors`) and different weighting schemes (`weights`). The `GridSearchCV` instance `knn_gridsearcher` is then created with these parameters, and the `fit` method is called to perform the grid search on the training data.\n",
    "\n",
    "**Try using `GridSearchCV` on your training data to find the optimal hyperparameters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    }
   ],
   "source": [
    "# Import the GridSearchCV class from the sklearn.model_selection module\n",
    "# GridSearchCV is used to perform an exhaustive search over specified parameter values for an estimator\n",
    "# Type annotation: 'GridSearchCV' is a class that will be instantiated and used for hyperparameter tuning\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameters to be tested in the grid search\n",
    "# 'knn_params' is a dictionary where keys are hyperparameter names and values are lists of parameter settings to try\n",
    "# - 'n_neighbors': List of integers representing the number of neighbors to use\n",
    "# - 'weights': List of strings representing the weight function to use ('uniform' or 'distance')\n",
    "# - 'metric': List of strings representing the distance metric to use ('euclidean' or 'manhattan')\n",
    "\n",
    "knn_params: dict[str, list] = {\n",
    "    'n_neighbors': [1, 3, 5, 9, 15, 21],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# Instantiate the GridSearchCV with the KNeighborsClassifier and the hyperparameters to search\n",
    "# - 'estimator': KNeighborsClassifier instance to fit\n",
    "# - 'param_grid': Dictionary containing hyperparameters to be tested\n",
    "# - 'cv': Number of cross-validation folds\n",
    "# - 'verbose': Level of verbosity (1 for limited output)\n",
    "# - 'n_jobs': Number of CPU cores to use (-1 to use all available cores)\n",
    "# Type annotation:\n",
    "# - 'knn_gridsearch': GridSearchCV instance configured for hyperparameter tuning\n",
    "\n",
    "knn_gridsearch: GridSearchCV = GridSearchCV(KNeighborsClassifier(),\n",
    "                                            knn_params,\n",
    "                                            cv=5,\n",
    "                                            verbose=1,\n",
    "                                            n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV to the training data\n",
    "# The 'fit' method performs the grid search over the specified hyperparameters and fits the estimator with the best found parameters\n",
    "# Type annotations:\n",
    "# - 'X_train': np.ndarray containing the training set predictor variables\n",
    "# - 'y_train': np.ndarray containing the training set target values (binary outcomes)\n",
    "# - The result of 'fit' is the GridSearchCV instance with the best found parameters stored internally\n",
    "\n",
    "knn_gridsearch = knn_gridsearch.fit(X_train, y_train)\n",
    "\n",
    "# After fitting, 'knn_gridsearch' contains the best parameters and can be used to make predictions and evaluate model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the Outcomes of the Grid Search\n",
    "\n",
    "After completing the grid search process (which may take some time), we can extract various pieces of valuable information and objects from the `gridsearch` object. These are stored as attributes and provide insights into the search results:\n",
    "\n",
    "| Property | Description |\n",
    "| --- | --- |\n",
    "| results.param_grid | Shows the range of parameters that were explored during the grid search. |\n",
    "| results.best_score_ | Indicates the highest mean cross-validated score achieved during the search. |\n",
    "| results.best_estimator_ | Refers to the model that attained the best score. This model is fully usable and can be called for predictions. |\n",
    "| results.best_params_ | Lists the specific parameters that resulted in the highest score. |\n",
    "| results.cv_results_ | Provides detailed results of the cross-validation process, including scores and the corresponding parameters. |\n",
    "\n",
    "**Print the best score identified during the grid search.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best mean cross-validated score achieved during the grid search is: 0.6126\n"
     ]
    }
   ],
   "source": [
    "# Extract and print the best score from the grid search results\n",
    "# The 'best_score_' attribute of the GridSearchCV instance contains the highest mean cross-validated score achieved during the search\n",
    "# This score represents the best performance of the KNeighborsClassifier with the optimal hyperparameters identified by the grid search\n",
    "# Type annotations:\n",
    "# - 'knn_gridsearch': GridSearchCV instance containing the results of the hyperparameter tuning\n",
    "# - The 'best_score_' attribute is a float representing the best mean cross-validated score\n",
    "\n",
    "best_score: float = knn_gridsearch.best_score_\n",
    "\n",
    "# Print the best score to understand the optimal performance achieved during the grid search\n",
    "# This helps in comparing the optimized model's performance against the default model and the baseline\n",
    "print(f\"The best mean cross-validated score achieved during the grid search is: {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters identified during the grid search are: {'metric': 'manhattan', 'n_neighbors': 21, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "# Extract the best hyperparameters identified during the grid search\n",
    "# The 'best_params_' attribute of the GridSearchCV instance contains a dictionary of the hyperparameters\n",
    "# that resulted in the highest mean cross-validated score during the search\n",
    "# These hyperparameters represent the optimal settings for the KNeighborsClassifier on the training data\n",
    "\n",
    "# Type annotations:\n",
    "# - 'knn_gridsearch': GridSearchCV instance containing the results of the hyperparameter tuning\n",
    "# - The 'best_params_' attribute is a dictionary where keys are hyperparameter names (str) and values are the optimal settings (can be various types depending on the hyperparameter)\n",
    "\n",
    "best_params: dict[str, any] = knn_gridsearch.best_params_\n",
    "\n",
    "# Print the best hyperparameters to understand the optimal settings identified during the grid search\n",
    "# This helps in knowing which hyperparameters (e.g., number of neighbors, weight function, distance metric) resulted in the best model performance\n",
    "print(f\"The best hyperparameters identified during the grid search are: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys of the cross-validation results: dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_metric', 'param_n_neighbors', 'param_weights', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score'])\n"
     ]
    }
   ],
   "source": [
    "# Display the keys of the cross-validation results from the grid search\n",
    "# The 'cv_results_' attribute of the GridSearchCV instance contains detailed results of the cross-validation process\n",
    "# It is a dictionary where keys are strings representing different metrics and parameter settings evaluated during the search\n",
    "# These keys include information such as the mean and standard deviation of the scores, the parameters tested, and the fit times\n",
    "\n",
    "# Type annotations:\n",
    "# - 'knn_gridsearch': GridSearchCV instance containing the results of the hyperparameter tuning\n",
    "# - The 'cv_results_' attribute is a dictionary where keys are strings and values are arrays or lists containing the detailed cross-validation results\n",
    "# - The 'keys()' method returns a view object displaying a list of all the keys in the 'cv_results_' dictionary\n",
    "\n",
    "cv_results_keys = knn_gridsearch.cv_results_.keys()\n",
    "\n",
    "# Print the keys of the cross-validation results to understand the available metrics and information captured during the grid search\n",
    "# This helps in analyzing the performance and behavior of the model with different hyperparameter settings\n",
    "print(f\"Keys of the cross-validation results: {cv_results_keys}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique hyperparameter combinations evaluated during the grid search: 24\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of parameter combinations evaluated during the grid search\n",
    "# 'knn_gridsearch.cv_results_' is a dictionary containing detailed results of the cross-validation process\n",
    "# The 'params' key in this dictionary contains a list of dictionaries, each representing a specific combination of hyperparameters tested\n",
    "# By calculating the length of this list, we can determine the total number of unique hyperparameter combinations evaluated during the grid search\n",
    "# Type annotations:\n",
    "# - 'knn_gridsearch': GridSearchCV instance containing the results of the hyperparameter tuning\n",
    "# - 'cv_results_': Dictionary where keys are strings and values are arrays or lists containing detailed cross-validation results\n",
    "# - 'params': List of dictionaries, each representing a specific combination of hyperparameters tested\n",
    "# - The 'len' function returns an integer representing the number of items in a list\n",
    "\n",
    "num_combinations: int = len(knn_gridsearch.cv_results_['params'])\n",
    "\n",
    "# Print the number of parameter combinations evaluated during the grid search\n",
    "# This helps in understanding the scope of the grid search and the number of different hyperparameter settings that were tested\n",
    "print(f\"Number of unique hyperparameter combinations evaluated during the grid search: {num_combinations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>weights</th>\n",
       "      <th>Mean Test Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>euclidean</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.560911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>euclidean</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.560911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>euclidean</td>\n",
       "      <td>3</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.572415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>euclidean</td>\n",
       "      <td>3</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.572415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>euclidean</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.592170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>euclidean</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.592170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>euclidean</td>\n",
       "      <td>9</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.605467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>euclidean</td>\n",
       "      <td>9</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.605467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>euclidean</td>\n",
       "      <td>15</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.606182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>euclidean</td>\n",
       "      <td>15</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.606182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>euclidean</td>\n",
       "      <td>21</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.610849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>euclidean</td>\n",
       "      <td>21</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.610849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>manhattan</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.560547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>manhattan</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.560547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>manhattan</td>\n",
       "      <td>3</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.571333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>manhattan</td>\n",
       "      <td>3</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.571333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>manhattan</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.598991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>manhattan</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.598991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>manhattan</td>\n",
       "      <td>9</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.600061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>manhattan</td>\n",
       "      <td>9</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.600061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>manhattan</td>\n",
       "      <td>15</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.606182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>manhattan</td>\n",
       "      <td>15</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.605463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>manhattan</td>\n",
       "      <td>21</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.612645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>manhattan</td>\n",
       "      <td>21</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.611209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       metric  n_neighbors   weights  Mean Test Scores\n",
       "0   euclidean            1   uniform          0.560911\n",
       "1   euclidean            1  distance          0.560911\n",
       "2   euclidean            3   uniform          0.572415\n",
       "3   euclidean            3  distance          0.572415\n",
       "4   euclidean            5   uniform          0.592170\n",
       "5   euclidean            5  distance          0.592170\n",
       "6   euclidean            9   uniform          0.605467\n",
       "7   euclidean            9  distance          0.605467\n",
       "8   euclidean           15   uniform          0.606182\n",
       "9   euclidean           15  distance          0.606182\n",
       "10  euclidean           21   uniform          0.610849\n",
       "11  euclidean           21  distance          0.610849\n",
       "12  manhattan            1   uniform          0.560547\n",
       "13  manhattan            1  distance          0.560547\n",
       "14  manhattan            3   uniform          0.571333\n",
       "15  manhattan            3  distance          0.571333\n",
       "16  manhattan            5   uniform          0.598991\n",
       "17  manhattan            5  distance          0.598991\n",
       "18  manhattan            9   uniform          0.600061\n",
       "19  manhattan            9  distance          0.600061\n",
       "20  manhattan           15   uniform          0.606182\n",
       "21  manhattan           15  distance          0.605463\n",
       "22  manhattan           21   uniform          0.612645\n",
       "23  manhattan           21  distance          0.611209"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame to store the results of the grid search\n",
    "# 'pd.DataFrame' is used to create a DataFrame from the 'params' key in 'cv_results_' which contains the hyperparameter combinations\n",
    "# Type annotations:\n",
    "# - 'knn_gridsearch': GridSearchCV instance containing the results of the hyperparameter tuning\n",
    "# - 'cv_results_': Dictionary where keys are strings and values are arrays or lists containing detailed cross-validation results\n",
    "# - 'params': List of dictionaries, each representing a specific combination of hyperparameters tested\n",
    "# - 'scores': pd.DataFrame is a DataFrame to store the hyperparameter combinations and their corresponding scores\n",
    "\n",
    "scores: pd.DataFrame = pd.DataFrame(knn_gridsearch.cv_results_['params'])\n",
    "\n",
    "# Add a new column to the DataFrame to store the mean test scores from the cross-validation results\n",
    "# The 'mean_test_score' key in 'cv_results_' contains the mean cross-validated scores for each hyperparameter combination\n",
    "# We add this column to the DataFrame to associate each hyperparameter combination with its corresponding mean test score\n",
    "# Type annotations:\n",
    "# - 'scores': pd.DataFrame is a DataFrame containing the hyperparameter combinations\n",
    "# - 'mean_test_score': np.ndarray is an array containing the mean cross-validated scores for each hyperparameter combination\n",
    "\n",
    "scores['Mean Test Scores'] = knn_gridsearch.cv_results_['mean_test_score']\n",
    "\n",
    "# Optionally, add a new column to the DataFrame to store the mean training scores from the cross-validation results\n",
    "# The 'mean_train_score' key in 'cv_results_' contains the mean training scores for each hyperparameter combination\n",
    "# Uncomment the following line to include the mean training scores in the DataFrame\n",
    "# Type annotations:\n",
    "# - 'mean_train_score': np.ndarray is an array containing the mean training scores for each hyperparameter combination\n",
    "\n",
    "# scores['Mean Training Scores'] = knn_gridsearch.cv_results_['mean_train_score']\n",
    "\n",
    "# Display the DataFrame to see the hyperparameter combinations and their corresponding mean test scores\n",
    "# This helps in analyzing the performance of different hyperparameter settings and identifying the optimal combination\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     0.560911\n",
       "3     0.572415\n",
       "5     0.592170\n",
       "7     0.605467\n",
       "9     0.606182\n",
       "11    0.610849\n",
       "13    0.560547\n",
       "15    0.571333\n",
       "17    0.598991\n",
       "19    0.600061\n",
       "21    0.605463\n",
       "23    0.611209\n",
       "Name: Mean Test Scores, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the rows from the 'scores' DataFrame where the 'weights' column is equal to 'distance'\n",
    "# The 'scores' DataFrame contains the results of the grid search, including hyperparameter combinations and their corresponding mean test scores\n",
    "# We use boolean indexing to filter the DataFrame and select only the rows where the 'weights' column has the value 'distance'\n",
    "# Type annotations:\n",
    "# - 'scores': pd.DataFrame is the DataFrame containing the hyperparameter combinations and their mean test scores\n",
    "# - 'filtered_scores': pd.Series is a Series containing the mean test scores for the hyperparameter combinations with 'weights' set to 'distance'\n",
    "\n",
    "filtered_scores: pd.Series = scores[scores['weights'] == 'distance']['Mean Test Scores']\n",
    "\n",
    "# Display the filtered scores\n",
    "# This Series contains the mean test scores for the hyperparameter combinations where the 'weights' parameter is set to 'distance'\n",
    "# It helps in understanding the performance of the KNeighborsClassifier with different hyperparameter settings, specifically focusing on the 'distance' weighting scheme\n",
    "filtered_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the mean test scores for different hyperparameter settings\n",
    "# We will create three separate plots to visualize the mean test scores for different values of 'n_neighbors' and different 'weights' settings\n",
    "# This helps in understanding the performance of the KNeighborsClassifier with various hyperparameter configurations\n",
    "\n",
    "# Import the matplotlib.pyplot module for plotting\n",
    "# 'plt' is a commonly used alias for the module\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the mean test scores for different values of 'n_neighbors'\n",
    "# We filter the 'scores' DataFrame to include only rows where 'n_neighbors' is greater than 0\n",
    "# The 'plot' method creates a line plot of the 'Mean Test Scores' column for these rows\n",
    "# Type annotations:\n",
    "# - 'scores': pd.DataFrame is the DataFrame containing the hyperparameter combinations and their mean test scores\n",
    "# - 'filtered_scores': pd.Series is a Series containing the mean test scores for the hyperparameter combinations with 'n_neighbors' > 0\n",
    "scores[scores['n_neighbors'] > 0]['Mean Test Scores'].plot(label='n_neighbors > 0')\n",
    "\n",
    "# Plot the mean test scores for the hyperparameter combinations with 'weights' set to 'distance'\n",
    "# We filter the 'scores' DataFrame to include only rows where the 'weights' column has the value 'distance'\n",
    "# The 'plot' method creates a line plot of the 'Mean Test Scores' column for these rows\n",
    "# Type annotations:\n",
    "# - 'filtered_scores': pd.Series is a Series containing the mean test scores for the hyperparameter combinations with 'weights' set to 'distance'\n",
    "scores[scores['weights'] == 'distance']['Mean Test Scores'].plot(label='weights=distance')\n",
    "\n",
    "# Plot the mean test scores for the hyperparameter combinations with 'weights' set to 'uniform'\n",
    "# We filter the 'scores' DataFrame to include only rows where the 'weights' column has the value 'uniform'\n",
    "# The 'plot' method creates a line plot of the 'Mean Test Scores' column for these rows\n",
    "# Type annotations:\n",
    "# - 'filtered_scores': pd.Series is a Series containing the mean test scores for the hyperparameter combinations with 'weights' set to 'uniform'\n",
    "scores[scores['weights'] == 'uniform']['Mean Test Scores'].plot(label='weights=uniform')\n",
    "\n",
    "# Add a legend to the plot to distinguish between the different lines\n",
    "plt.legend()\n",
    "\n",
    "# Add a title to the plot for better understanding of what is being visualized\n",
    "plt.title('Mean Test Scores for Different Hyperparameter Settings')\n",
    "\n",
    "# Add labels to the x-axis and y-axis for clarity\n",
    "plt.xlabel('Hyperparameter Combination Index')\n",
    "plt.ylabel('Mean Test Score')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assign the optimal model identified by the grid search (`best_estimator_`) to a variable and evaluate its performance on the test dataset.**\n",
    "\n",
    "Compare this optimized model's accuracy with the baseline accuracy and the accuracy of your initial, default KNN model. Assess how much improvement, if any, has been achieved by tuning the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the best estimator identified by the GridSearchCV to a variable\n",
    "# The 'best_estimator_' attribute of the GridSearchCV instance contains the model with the optimal hyperparameters\n",
    "# This model achieved the highest mean cross-validated score during the grid search\n",
    "# Type annotations:\n",
    "# - 'knn_gridsearch': GridSearchCV instance containing the results of the hyperparameter tuning\n",
    "# - 'best_knn': KNeighborsClassifier instance representing the model with the best hyperparameters identified by the grid search\n",
    "\n",
    "best_knn: KNeighborsClassifier = knn_gridsearch.best_estimator_\n",
    "\n",
    "# Use the best KNeighborsClassifier model to make predictions on the test dataset\n",
    "# The 'predict' method generates predictions based on the input predictor matrix 'X_test'\n",
    "# These predictions are the model's estimates of the target values for the test set\n",
    "# Type annotations:\n",
    "# - 'X_test': np.ndarray containing the predictor variables for the test set\n",
    "# - 'y_pred': np.ndarray containing the predicted target values for the test set (binary outcomes)\n",
    "\n",
    "y_pred: np.ndarray = best_knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized KNN model accuracy on the test set: 0.6254\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance of the best KNeighborsClassifier model on the test dataset\n",
    "# The 'score' method computes the mean accuracy of the model on the given test data and labels\n",
    "# It returns the proportion of correctly predicted labels out of the total number of labels in the test set\n",
    "# This accuracy score helps in assessing how well the optimized model generalizes to unseen data\n",
    "\n",
    "# Type annotations:\n",
    "# - 'best_knn': KNeighborsClassifier instance representing the model with the best hyperparameters identified by the grid search\n",
    "# - 'X_test': np.ndarray containing the predictor variables for the test set\n",
    "# - 'y_test': np.ndarray containing the true target values for the test set (binary outcomes)\n",
    "# - The result of 'score' is a float representing the accuracy of the model on the test set\n",
    "\n",
    "test_accuracy: float = best_knn.score(X_test, y_test)\n",
    "\n",
    "# Print the accuracy of the best KNeighborsClassifier model on the test set\n",
    "# This helps in comparing the performance of the optimized model against the baseline accuracy and the initial, default model\n",
    "print(f\"Optimized KNN model accuracy on the test set: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy (proportion of home team wins in the test set): 0.6030\n",
      "Default KNN model accuracy on the test set: 0.5726\n"
     ]
    }
   ],
   "source": [
    "# This cell contains code to print the baseline accuracy and the accuracy of the default KNeighborsClassifier (KNN) model\n",
    "# We will use extensive comments and type annotations to explain the code and its purpose\n",
    "\n",
    "# Print the baseline accuracy\n",
    "# The baseline accuracy is calculated as the mean of the true target values in the test set (y_test)\n",
    "# This represents the proportion of home team wins in the test set, which is used as a simple benchmark for model performance\n",
    "# Type annotations:\n",
    "# - 'y_test': np.ndarray containing the true target values for the test set (binary outcomes)\n",
    "# - 'np.mean': Function that calculates the mean of an array\n",
    "# - The result of 'np.mean(y_test)' is a float representing the baseline accuracy\n",
    "\n",
    "baseline_accuracy: float = np.mean(y_test)\n",
    "\n",
    "# Print the baseline accuracy with a descriptive label\n",
    "# This helps in understanding the performance of the simplest model that always predicts a home team win\n",
    "print(f'Baseline accuracy (proportion of home team wins in the test set): {baseline_accuracy:.4f}')\n",
    "\n",
    "# Print the accuracy of the default KNeighborsClassifier (KNN) model on the test set\n",
    "# The default KNN model is evaluated using the 'score' method, which computes the mean accuracy on the given test data and labels\n",
    "# This accuracy score helps in assessing how well the default model generalizes to unseen data\n",
    "# Type annotations:\n",
    "# - 'knn': KNeighborsClassifier instance representing the default KNN model\n",
    "# - 'X_test': np.ndarray containing the predictor variables for the test set\n",
    "# - 'y_test': np.ndarray containing the true target values for the test set (binary outcomes)\n",
    "# - The result of 'knn.score(X_test, y_test)' is a float representing the accuracy of the default KNN model on the test set\n",
    "\n",
    "default_knn_accuracy: float = knn.score(X_test, y_test)\n",
    "\n",
    "# Print the accuracy of the default KNN model with a descriptive label\n",
    "# This helps in comparing the performance of the default model against the baseline accuracy\n",
    "print(f'Default KNN model accuracy on the test set: {default_knn_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   host lost       0.54      0.36      0.43       391\n",
      "    host won       0.66      0.80      0.72       594\n",
      "\n",
      "    accuracy                           0.63       985\n",
      "   macro avg       0.60      0.58      0.58       985\n",
      "weighted avg       0.61      0.63      0.61       985\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the classification_report function from the sklearn.metrics module\n",
    "# This function generates a detailed classification report showing the main classification metrics\n",
    "# Type annotations:\n",
    "# - 'classification_report': Function that computes the classification metrics based on the true and predicted labels\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define a list of target names for the classification report\n",
    "# These names correspond to the classes in the target variable (y_test)\n",
    "# - 'host lost': Class label representing the scenario where the host team lost\n",
    "# - 'host won': Class label representing the scenario where the host team won\n",
    "# Type annotations:\n",
    "# - 'target_names': List of strings representing the names of the classes in the target variable\n",
    "\n",
    "target_names: list[str] = ['host lost', 'host won']\n",
    "\n",
    "# Print the classification report for the test set predictions\n",
    "# The classification_report function generates a text report showing the main classification metrics\n",
    "# - 'y_test': np.ndarray containing the true target values for the test set (binary outcomes)\n",
    "# - 'y_pred': np.ndarray containing the predicted target values for the test set (binary outcomes)\n",
    "# - 'target_names': List of strings representing the names of the classes in the target variable\n",
    "# The report includes metrics such as precision, recall, f1-score, and support for each class\n",
    "# This helps in evaluating the performance of the model on the test set\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Word of Caution on Grid Searching\n",
    "\n",
    "Sklearn models often come with numerous hyperparameters, each having a range of possible values. While it might be tempting to search across a vast array of these options, this approach is generally not advisable.\n",
    "\n",
    "It's crucial to remember that **GridSearchCV explores all possible combinations of hyperparameters specified in the parameter dictionary!**\n",
    "\n",
    "For instance, the KNeighborsClassifier (KNN) model can be instantiated with a variety of options beyond those we've previously considered. Imagine the following parameter dictionary:\n",
    "\n",
    "```python\n",
    "parameter_grid = {\n",
    "    'n_neighbors': range(1, 151),\n",
    "    'weights': ['uniform', 'distance', custom_function],\n",
    "    'algorithm': ['ball_tree', 'kd_tree', 'brute', 'auto'],\n",
    "    'leaf_size': range(1, 152),\n",
    "    'metric': ['minkowski', 'euclidean'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "**How many different combinations would need to be tested?**\n",
    "\n",
    "| Parameter | Potential Values | Unique Values |\n",
    "| --- | --- | --- |\n",
    "| n_neighbors | int range 1-150 | 150 |\n",
    "| weights | strs: \"uniform\", \"distance,\" or user-defined function | 3 |\n",
    "| algorithm | strs: \"ball_tree,\" \"kd_tree,\" \"brute,\" \"auto\" | 4 |\n",
    "| leaf_size | int range 1-151 | 151 |\n",
    "| metric | str: \"minkowski\" or \"euclidean\" type | 2 |\n",
    "| p | int: 1=manhattan_distance, 2=euclidean_distance | 2 |\n",
    "|  | 150 \\* 3 \\* 4 \\* 151 \\* 2 \\* 2 = n combinations | 1,087,200 |\n",
    "\n",
    "This results in over a million combinations even before accounting for the number of cross-validation folds!\n",
    "\n",
    "If not managed carefully, grid searching can become overwhelming very quickly. Many of the hyperparameters in the example above are either redundant or not useful.\n",
    "\n",
    "It is extremely important to understand what the hyperparameters do and to critically evaluate which ranges are useful and relevant to your model!\n",
    "\n",
    "## Grid Search for Logistic Regression with Regularization Penalties\n",
    "\n",
    "Logistic regression models can incorporate Lasso and Ridge regularization techniques to prevent overfitting and improve model generalization. The `LogisticRegression` class in scikit-learn allows the use of these regularization methods through specific hyperparameters. Here are the primary hyperparameters related to regularization:\n",
    "\n",
    "| Argument | Description |\n",
    "| --- | --- |\n",
    "| penalty | Specifies the type of regularization: 'l1' for Lasso, which can drive some coefficients to zero, and 'l2' for Ridge, which shrinks coefficients but does not set them to zero. |\n",
    "| solver | Required to be set to 'liblinear' when using Lasso regularization, as this solver supports L1 penalties. |\n",
    "| C | Represents the inverse of regularization strength, where smaller values indicate stronger regularization (equivalent to 1./alpha). |\n",
    "\n",
    "### Steps to Perform:\n",
    "\n",
    "1. **Fit and Validate a Default Logistic Regression Model:**\n",
    "    - Start by training a logistic regression model with default settings on the basketball dataset and evaluate its accuracy to establish a baseline performance.\n",
    "2. **Conduct a Grid Search for Hyperparameter Tuning:**\n",
    "    - Execute a grid search to explore various regularization strengths (`C` values) and both Lasso and Ridge penalties. This search will identify the optimal combination of hyperparameters.\n",
    "3. **Compare Accuracy of Optimized Model:**\n",
    "    - Assess the accuracy of the optimized logistic regression model on the test set and compare it to the baseline accuracy and the default model's performance. This comparison will help gauge the effectiveness of hyperparameter tuning.\n",
    "4. **Analyze Best Parameters:**\n",
    "    - Examine the best parameters identified by the grid search. Determine which penalty (Lasso or Ridge) and regularization strength were chosen. This insight can reveal characteristics about the data and what type of regularization is more suitable.\n",
    "5. **Evaluate Important Predictors:**\n",
    "    - If Lasso regularization was selected, inspect the non-zero coefficients in the optimized model to identify the most influential predictors. These predictors can provide valuable information about factors that significantly impact the outcome of winning a basketball game.\n",
    "\n",
    "By following these steps, you can effectively tune a logistic regression model with regularization, understand the importance of different predictors, and improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the LogisticRegression class from the sklearn.linear_model module\n",
    "# 'LogisticRegression' is a class used to create logistic regression models in scikit-learn\n",
    "# Type annotations:\n",
    "# - 'LogisticRegression': Class used to instantiate logistic regression models\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create an instance of the LogisticRegression model with default settings\n",
    "# This instance will be used as the base model for the grid search\n",
    "# Type annotations:\n",
    "# - 'lr': LogisticRegression instance representing the logistic regression model with default settings\n",
    "\n",
    "lr: LogisticRegression = LogisticRegression()\n",
    "\n",
    "# Define the parameter grid for the grid search\n",
    "# The parameter grid specifies the hyperparameters and their respective values to be explored during the search\n",
    "# - 'penalty': Specifies the type of regularization to use ('l1' for Lasso, 'l2' for Ridge)\n",
    "# - 'solver': Specifies the algorithm to use for optimization ('liblinear' supports L1 regularization)\n",
    "# - 'C': Specifies the inverse of regularization strength, explored over a logarithmic scale from 1e-5 to 1e0 (100 values)\n",
    "# Type annotations:\n",
    "# - 'gs_params': Dictionary where keys are strings and values are lists of hyperparameter values to be tested\n",
    "\n",
    "gs_params: dict = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear'],\n",
    "    'C': np.logspace(-5, 0, 100)\n",
    "}\n",
    "\n",
    "# Create an instance of GridSearchCV to perform the grid search with cross-validation\n",
    "# - The first argument is the base model (LogisticRegression instance) to be used for the search\n",
    "# - The second argument is the parameter grid (gs_params) specifying the hyperparameters to be explored\n",
    "# - 'cv': Number of cross-validation folds (5 in this case), used to evaluate the performance of each hyperparameter combination\n",
    "# - 'verbose': Level of verbosity (set to 1 for progress messages during the search)\n",
    "# - 'n_jobs': Number of parallel jobs to run (-1 means using all processors)\n",
    "# Type annotations:\n",
    "# - 'LogisticRegression': Class used to create logistic regression models\n",
    "# - 'GridSearchCV': Class used to perform an exhaustive search over specified parameter values\n",
    "# - 'lr_gridsearch': GridSearchCV instance representing the grid search with cross-validation\n",
    "\n",
    "lr_gridsearch: GridSearchCV = GridSearchCV(LogisticRegression(), gs_params, cv=5, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    }
   ],
   "source": [
    "# Fit the GridSearchCV object to the training data\n",
    "# This step involves training multiple logistic regression models using different combinations of hyperparameters specified in the parameter grid\n",
    "# The GridSearchCV object will perform cross-validation to evaluate the performance of each combination and identify the optimal hyperparameters\n",
    "\n",
    "# Type annotations:\n",
    "# - 'lr_gridsearch': GridSearchCV object that will perform the grid search with cross-validation\n",
    "# - 'X_train': np.ndarray containing the predictor variables (features) for the training set\n",
    "# - 'y_train': np.ndarray containing the target values (labels) for the training set (binary outcomes)\n",
    "# - The 'fit' method does not return a value but modifies the 'lr_gridsearch' instance in place\n",
    "\n",
    "lr_gridsearch = lr_gridsearch.fit(X_train, y_train)\n",
    "\n",
    "# After fitting, the 'lr_gridsearch' object will have additional attributes such as:\n",
    "# - 'best_estimator_': The model with the best hyperparameters identified by the grid search\n",
    "# - 'best_params_': A dictionary containing the hyperparameters of the best model\n",
    "# - 'best_score_': The mean cross-validated score of the best model\n",
    "# - 'cv_results_': A dictionary containing detailed results of the grid search, including scores for all evaluated hyperparameter combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score on the training data: 0.6608\n"
     ]
    }
   ],
   "source": [
    "# Access the best score achieved by the GridSearchCV object on the training data\n",
    "# The 'best_score_' attribute of the GridSearchCV instance contains the mean cross-validated score of the best model\n",
    "# This score represents the highest average performance across the cross-validation folds for the optimal hyperparameters\n",
    "\n",
    "# Type annotations:\n",
    "# - 'lr_gridsearch': GridSearchCV instance containing the results of the hyperparameter tuning\n",
    "# - The result of 'lr_gridsearch.best_score_' is a float representing the best mean cross-validated score\n",
    "\n",
    "best_training_score: float = lr_gridsearch.best_score_\n",
    "\n",
    "# Print the best score achieved on the training data\n",
    "# This helps in understanding the optimal model's performance during the training phase\n",
    "# The score is typically a measure of accuracy, but it depends on the scoring method used in the GridSearchCV\n",
    "\n",
    "print(f\"Best score on the training data: {best_training_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters on the training data: {'C': 0.0029836472402833404, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# Access the best hyperparameters identified by the GridSearchCV object\n",
    "# The 'best_params_' attribute of the GridSearchCV instance contains a dictionary of the optimal hyperparameters\n",
    "# These hyperparameters achieved the highest mean cross-validated score during the grid search\n",
    "\n",
    "# Type annotations:\n",
    "# - 'lr_gridsearch': GridSearchCV instance containing the results of the hyperparameter tuning\n",
    "# - The result of 'lr_gridsearch.best_params_' is a dictionary containing the best hyperparameters\n",
    "\n",
    "best_params: dict = lr_gridsearch.best_params_\n",
    "\n",
    "# Print the best hyperparameters identified by the GridSearchCV object\n",
    "# This helps in understanding which hyperparameter values led to the best model performance\n",
    "# The dictionary typically includes keys corresponding to the hyperparameters and values representing the optimal settings\n",
    "\n",
    "print(f\"Best parameters on the training data: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the best estimator identified by the GridSearchCV to a variable\n",
    "# The 'best_estimator_' attribute of the GridSearchCV instance contains the logistic regression model with the optimal hyperparameters\n",
    "# This model achieved the highest mean cross-validated score during the grid search\n",
    "\n",
    "# Type annotations:\n",
    "# - 'lr_gridsearch': GridSearchCV instance containing the results of the hyperparameter tuning\n",
    "# - 'best_lr': LogisticRegression instance representing the model with the best hyperparameters identified by the grid search\n",
    "\n",
    "best_lr: LogisticRegression = lr_gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Logistic Regression model accuracy on the test set: 0.6660\n"
     ]
    }
   ],
   "source": [
    "# Score the best logistic regression model on the test dataset\n",
    "# The 'score' method computes the mean accuracy of the model on the given test data and labels\n",
    "# It returns the proportion of correctly predicted labels out of the total number of labels in the test set\n",
    "\n",
    "# Type annotations:\n",
    "# - 'best_lr': LogisticRegression instance representing the model with the best hyperparameters identified by the grid search\n",
    "# - 'X_test': np.ndarray containing the predictor variables for the test set\n",
    "# - 'y_test': np.ndarray containing the true target values for the test set (binary outcomes)\n",
    "# - The result of 'score' is a float representing the accuracy of the model on the test set\n",
    "\n",
    "test_accuracy: float = best_lr.score(X_test, y_test)\n",
    "\n",
    "# Print the accuracy of the best logistic regression model on the test set\n",
    "# This helps in understanding how well the optimized model generalizes to unseen data\n",
    "print(f\"Optimized Logistic Regression model accuracy on the test set: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   coef          feature\n",
      "0   0.0    Host_HostRank\n",
      "1   0.0    Host_GameRank\n",
      "2   0.0  Guest_GuestRank\n",
      "3   0.0   Guest_GameRank\n",
      "4   0.0   host_win_count\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame to store the coefficients of the best logistic regression model and their corresponding feature names\n",
    "# The DataFrame is constructed using a dictionary where:\n",
    "# - The 'coef' key is associated with the coefficients of the best logistic regression model\n",
    "# - The 'feature' key is associated with the names of the features (columns) in the predictor matrix 'X'\n",
    "\n",
    "# Type annotations:\n",
    "# - 'best_lr': LogisticRegression instance representing the model with the best hyperparameters identified by the grid search\n",
    "# - 'X': DataFrame containing the predictor variables (features) for the dataset\n",
    "# - 'pd.DataFrame': Class used to create a DataFrame\n",
    "# - 'coef_df': DataFrame containing the coefficients and feature names\n",
    "\n",
    "coef_df: pd.DataFrame = pd.DataFrame({\n",
    "    'coef': best_lr.coef_[0],  # Extract the coefficients of the best logistic regression model (first row)\n",
    "    'feature': X_columns       # Extract the feature names from the columns of the predictor matrix 'X'\n",
    "})\n",
    "\n",
    "# Print the first few rows of the DataFrame to verify its contents\n",
    "# This helps in understanding the relationship between the coefficients and the feature names\n",
    "print(coef_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   coef          feature  abs_coef\n",
      "0   0.0    Host_HostRank       0.0\n",
      "1   0.0    Host_GameRank       0.0\n",
      "2   0.0  Guest_GuestRank       0.0\n",
      "3   0.0   Guest_GameRank       0.0\n",
      "4   0.0   host_win_count       0.0\n"
     ]
    }
   ],
   "source": [
    "# Add a new column 'abs_coef' to the DataFrame 'coef_df'\n",
    "# The new column will store the absolute values of the coefficients from the 'coef' column\n",
    "# The 'np.abs' function is used to compute the absolute value of each coefficient\n",
    "# Type annotations:\n",
    "# - 'coef_df': DataFrame containing the coefficients and feature names\n",
    "# - 'coef': Series within the DataFrame representing the coefficients of the logistic regression model\n",
    "# - 'abs_coef': Series within the DataFrame representing the absolute values of the coefficients\n",
    "\n",
    "coef_df['abs_coef'] = np.abs(coef_df.coef)\n",
    "\n",
    "# Print the first few rows of the updated DataFrame to verify the new column\n",
    "# This helps in understanding the relationship between the original coefficients and their absolute values\n",
    "print(coef_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        coef        feature  abs_coef\n",
      "8   0.218062    game_behind  0.218062\n",
      "0   0.000000  Host_HostRank  0.000000\n",
      "54  0.000000    gTOV%_avg10  0.000000\n",
      "62  0.000000     g3PA_avg10  0.000000\n",
      "61  0.000000      g3P_avg10  0.000000\n"
     ]
    }
   ],
   "source": [
    "# Sort the DataFrame (coef_df) by the 'abs_coef' column in descending order\n",
    "# The 'sort_values' method is used to sort the DataFrame by a specified column or columns\n",
    "# The 'ascending' parameter is set to False to sort in descending order\n",
    "# The 'inplace' parameter is set to True to modify the DataFrame in place, rather than returning a sorted copy\n",
    "\n",
    "# Type annotations:\n",
    "# - 'coef_df': DataFrame containing the coefficients, feature names, and absolute values of the coefficients\n",
    "# - The 'sort_values' method returns None when 'inplace' is set to True, and modifies 'coef_df' in place\n",
    "\n",
    "coef_df.sort_values('abs_coef', ascending=False, inplace=True)\n",
    "\n",
    "# Print the first few rows of the sorted DataFrame to verify the result\n",
    "# This helps in understanding the features with the highest absolute values of coefficients, which are the most influential predictors\n",
    "print(coef_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       coef      feature  abs_coef\n",
      "8  0.218062  game_behind  0.218062\n"
     ]
    }
   ],
   "source": [
    "# This cell contains code to filter the DataFrame (coef_df) to show only the non-zero coefficients and their corresponding predictors\n",
    "# We will use extensive comments and type annotations to explain the code and its purpose\n",
    "\n",
    "# Filter the DataFrame to include only the rows where the coefficient is not equal to zero\n",
    "# The 'coef' column is checked for non-zero values, and only those rows are retained in the filtered DataFrame\n",
    "# The resulting DataFrame will show the predictors with non-zero coefficients, indicating their importance in the model\n",
    "\n",
    "# Type annotations:\n",
    "# - 'coef_df': DataFrame containing the coefficients, feature names, and absolute values of the coefficients\n",
    "# - The result of 'coef_df[coef_df.coef != 0]' is a DataFrame containing only the rows with non-zero coefficients\n",
    "\n",
    "non_zero_coef_df: pd.DataFrame = coef_df[coef_df.coef != 0]\n",
    "\n",
    "# Print the filtered DataFrame to show the non-zero coefficients and their corresponding predictors\n",
    "# This helps in identifying the features that have a significant impact on the model's predictions\n",
    "print(non_zero_coef_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this model, the variable \"Game_behind\" emerges as the most significant predictor—and potentially the sole indicator—of a team's likelihood to win. This suggests that \"Game_behind\" is a critical factor in determining the outcome of a game, overshadowing other possible predictors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
